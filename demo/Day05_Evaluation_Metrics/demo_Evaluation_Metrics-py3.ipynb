{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TPV, FPV, AUC, confusion matrix, NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choice of metrics influences how the performance of machine learning algorithms is measured and compared. They influence how you weight the importance of different characteristics in the results and your ultimate choice of which algorithm to choose.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "- Classification Accuracy\n",
    "- AUC â€“ ROC\n",
    "- Confusion Matrix\n",
    "- NDCG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset in use:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics are demonstrated for classification machine learning problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pima Indians Diabetes Data Set: https://archive.ics.uci.edu/ml/datasets/pima+indians+diabetes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a binary classification problem where all of the input variables are numeric.\n",
    "\n",
    "**Attributes:**\n",
    "\n",
    "1. Number of times pregnant \n",
    "2. Plasma glucose concentration a 2 hours in an oral glucose tolerance test \n",
    "3. Diastolic blood pressure (mm Hg) \n",
    "4. Triceps skin fold thickness (mm) \n",
    "5. 2-Hour serum insulin (mu U/ml) \n",
    "6. Body mass index (weight in kg/(height in m)^2) \n",
    "7. Diabetes pedigree function \n",
    "8. Age (years) \n",
    "9. Class variable (0 or 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description: **\n",
    "\n",
    "The diagnostic, binary-valued variable investigated is whether the\n",
    "patient shows signs of diabetes according to World Health Organization\n",
    "criteria. Pima Indians are a group of Native Americans living near Phoenix, Arizona, USA.\n",
    "\n",
    "Their ADAP algorithm, an adaptive learning routine that generates and executes digital analogs of perceptron-like devices, makes a real-valued prediction between\n",
    "0 and 1.  This was transformed into a binary decision using a cutoff of \n",
    "0.448.  Using 576 training instances, the sensitivity and specificity\n",
    "of their algorithm was 76% on the remaining 192 instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's have a look at the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preg</th>\n",
       "      <th>plas</th>\n",
       "      <th>pres</th>\n",
       "      <th>skin</th>\n",
       "      <th>test</th>\n",
       "      <th>mass</th>\n",
       "      <th>pedi</th>\n",
       "      <th>age</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>148</td>\n",
       "      <td>72</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>33.6</td>\n",
       "      <td>0.627</td>\n",
       "      <td>50</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>66</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>26.6</td>\n",
       "      <td>0.351</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>183</td>\n",
       "      <td>64</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.3</td>\n",
       "      <td>0.672</td>\n",
       "      <td>32</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>89</td>\n",
       "      <td>66</td>\n",
       "      <td>23</td>\n",
       "      <td>94</td>\n",
       "      <td>28.1</td>\n",
       "      <td>0.167</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>40</td>\n",
       "      <td>35</td>\n",
       "      <td>168</td>\n",
       "      <td>43.1</td>\n",
       "      <td>2.288</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preg  plas  pres  skin  test  mass   pedi  age  class\n",
       "0     6   148    72    35     0  33.6  0.627   50      1\n",
       "1     1    85    66    29     0  26.6  0.351   31      0\n",
       "2     8   183    64     0     0  23.3  0.672   32      1\n",
       "3     1    89    66    23    94  28.1  0.167   21      0\n",
       "4     0   137    40    35   168  43.1  2.288   33      1"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/pima-indians-diabetes/pima-indians-diabetes.data\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv(url, names=names)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert dataframe into array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   6.   ,  148.   ,   72.   , ...,    0.627,   50.   ,    1.   ],\n",
       "       [   1.   ,   85.   ,   66.   , ...,    0.351,   31.   ,    0.   ],\n",
       "       [   8.   ,  183.   ,   64.   , ...,    0.672,   32.   ,    1.   ],\n",
       "       ..., \n",
       "       [   5.   ,  121.   ,   72.   , ...,    0.245,   30.   ,    0.   ],\n",
       "       [   1.   ,  126.   ,   60.   , ...,    0.349,   47.   ,    1.   ],\n",
       "       [   1.   ,   93.   ,   70.   , ...,    0.315,   23.   ,    0.   ]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array = dataframe.values\n",
    "array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the attributes by data values and class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = array[:,0:8] # [preg, plas, pres, skin, test, mass, pedi, age]\n",
    "Y = array[:,8] # [class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All metrics evaluate the same algorithms, Logistic Regression for classification. A 10-fold cross-validation test harness is used to demonstrate each metric, because this is the most likely scenario where you will be employing different algorithm evaluation metrics.\n",
    "\n",
    "Cross_val_score function is used to report the performance in each metric. All scores are reported so that they can be sorted in ascending order (largest score is best)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification Accuracy\n",
    "= number of correct predictions made as a ratio of all predictions made."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " It is really only suitable when there are an equal number of observations in each class (which is rarely the case) and that all predictions and prediction errors are equally important, which is often not the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 76.951% (4.841%)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Accuracy\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'accuracy'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"Accuracy: %.3f%% (%.3f%%)\" %(results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Area Under ROC Curve (AUC)\n",
    "= performance metric for binary classification problems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"irc_mi\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/4/4f/ROC_curves.svg/1280px-ROC_curves.svg.png\" onload=\"google.aft&amp;&amp;google.aft(this)\" width=\"500\" height=\"500\" style=\"margin-left: 5px;\" alt=\"Image result for Area under roc curve\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AUC represents a modelâ€™s ability to discriminate between positive and negative classes. An area of 1.0 represents a model that made all predictions perfectly. An area of 0.5 represents a model as good as random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.824 (0.041)\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification ROC AUC\n",
    "\n",
    "seed = 7\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "scoring = 'roc_auc'\n",
    "results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "print(\"AUC: %.3f (%.3f)\" % (results.mean(), results.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result shows AUC is relatively close to 1 and greater than 0.5, suggesting some skill in the predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Confusion Matrix\n",
    "= presentation of the accuracy of a model with two or more classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"irc_mi\" src=\"https://de.mathworks.com/matlabcentral/mlc-downloads/downloads/submissions/60900/versions/11/screenshot.png\" onload=\"google.aft&amp;&amp;google.aft(this)\" width=\"500\" height=\"500\" style=\"margin-left: 1px;\" alt=\"Image result for confusion matrix\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It creates a table that presents predictions on the x-axis and accuracy outcomes on the y-axis. The cells of the table are the number of predictions made by a machine learning algorithm.\n",
    "\n",
    "For example, a machine learning algorithm can predict 0 or 1 and each prediction may actually have been a 0 or 1. Predictions for 0 that were actually 0 appear in the cell for prediction=0 and actual=0, whereas predictions for 0 that were actually 1 appear in the cell for prediction = 0 and actual=1. And so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate a confusion matrix for a set of prediction by a model on a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[141  21]\n",
      " [ 41  51]]\n"
     ]
    }
   ],
   "source": [
    "# Cross Validation Classification Confusion Matrix\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "predicted = model.predict(X_test)\n",
    "matrix = confusion_matrix(Y_test, predicted)\n",
    "print(matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although the array is printed without headings, you can see that the majority of the predictions fall on the diagonal line of the matrix (which are correct predictions)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Normalized Discounted Cumulative Gain (NDCG)\n",
    "= measures the performance of a recommendation system based on the graded relevance of the recommended entities. It varies from 0.0 to 1.0, with 1.0 representing the ideal ranking of the entities. This metric is commonly used in information retrieval and to evaluate the performance of web search engines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"irc_mi\" src=\"http://imageclef.org/system/files/ndcg.png\" onload=\"google.aft&amp;&amp;google.aft(this)\" width=\"385\" height=\"94\" style=\"margin-top: 1px;\" alt=\"Image result for ndcg\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-01-13 23:49:49--  https://raw.githubusercontent.com/telescopeuser/ranking_measures/master/measures.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.8.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.8.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7814 (7.6K) [text/plain]\n",
      "Saving to: â€˜measures.pyâ€™\n",
      "\n",
      "measures.py         100%[===================>]   7.63K  --.-KB/s    in 0.008s  \n",
      "\n",
      "2018-01-13 23:49:49 (921 KB/s) - â€˜measures.pyâ€™ saved [7814/7814]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download a customized library 'measures.py' for NDCG calculation\n",
    "!rm measures.py\n",
    "!wget https://raw.githubusercontent.com/telescopeuser/ranking_measures/master/measures.py\n",
    "# !wget https://github.com/telescopeuser/ranking_measures/blob/master/measures.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9600280799041041\n"
     ]
    }
   ],
   "source": [
    "import measures\n",
    "reference_list = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
    "predicted_list = [2, 1, 4, 3, 6, 5, 8, 7, 10, 9, 12, 11]\n",
    "print (measures.find_rankdcg(reference_list, predicted_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More ranking examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list L1: [9, 4, 4, 2, 2, 2, 1, 1, 1, 1]\n",
      "list L2: [9, 4, 4, 2, 2, 1, 2, 1, 1, 1]\n",
      "list L3: [4, 4, 2, 9, 2, 2, 1, 1, 1, 1]\n",
      "list L4: [1, 4, 4, 2, 2, 2, 9, 1, 1, 1]\n",
      "list L5: [1, 4, 4, 2, 2, 2, 1, 1, 1, 9]\n",
      "list L6: [1, 1, 1, 1, 2, 2, 2, 4, 4, 9]\n",
      "\n",
      "1. Perfect ordering: (L1, L1)\n",
      "\t DCG:\t\t\t24.68463499685107\n",
      "\t nDCG:\t\t\t1.0\n",
      "\t Precision:\t\t1.0\n",
      "\t Precision at k:\t1.0\n",
      "\t Average precision:\t1.0\n",
      "\t RankDCG:\t\t1.0\n",
      "\n",
      "2. Slightly wose case (low ranks): (L1, L2)\n",
      "\t DCG:\t\t\t24.651635001444305\n",
      "\t nDCG:\t\t\t0.9986631361812328\n",
      "\t Precision:\t\t0.8\n",
      "\t Precision at k:\t0.8\n",
      "\t Average precision:\t0.8875396825396826\n",
      "\t RankDCG:\t\t0.9749999999999999\n",
      "\n",
      "3. Further worsen case (hight ranks): (L1, L3)\n",
      "\t DCG:\t\t\t20.377809293434577\n",
      "\t nDCG:\t\t\t0.825526052786849\n",
      "\t Precision:\t\t0.7\n",
      "\t Precision at k:\t0.7\n",
      "\t Average precision:\t0.45464285714285707\n",
      "\t RankDCG:\t\t0.6500000000000002\n",
      "\n",
      "4. Placement of a high rank element into the low rank 'subgroup': (L1, L4)\n",
      "\t DCG:\t\t\t16.990261445443263\n",
      "\t nDCG:\t\t\t0.6882929987666679\n",
      "\t Precision:\t\t0.8\n",
      "\t Precision at k:\t0.8\n",
      "\t Average precision:\t0.6592063492063491\n",
      "\t RankDCG:\t\t0.3250000000000004\n",
      "\n",
      "5. Case #4 but with further misplacement of the hight rank element inside the low rank 'subgroup': (L1, L5)\n",
      "\t DCG:\t\t\t16.479333801133333\n",
      "\t nDCG:\t\t\t0.6675947934103762\n",
      "\t Precision:\t\t0.8\n",
      "\t Precision at k:\t0.8\n",
      "\t Average precision:\t0.6971031746031746\n",
      "\t RankDCG:\t\t0.3250000000000004\n",
      "\n",
      "6. The worst case (reverse ordering): (L1, L6)\n",
      "\t DCG:\t\t\t14.112379257972764\n",
      "\t nDCG:\t\t\t0.5717070258390707\n",
      "\t Precision:\t\t0.2\n",
      "\t Precision at k:\t0.2\n",
      "\t Average precision:\t0.1491269841269841\n",
      "\t RankDCG:\t\t0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import measures\n",
    "\n",
    "def test_measures(reference, hypothesis):\n",
    "    \"\"\"\n",
    "    Runs all rank-ordering evaluation measures on given pair of lists.\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"\\t DCG:\\t\\t\\t{0}\".format(measures.find_dcg(hypothesis)))\n",
    "    print(\"\\t nDCG:\\t\\t\\t{0}\".format(measures.find_ndcg(reference, hypothesis)))\n",
    "    print(\"\\t Precision:\\t\\t{0}\".format(measures.find_precision(reference, hypothesis)))\n",
    "    print(\"\\t Precision at k:\\t{0}\".format(measures.find_precision_k(reference, hypothesis, len(reference))))\n",
    "    print(\"\\t Average precision:\\t{0}\".format(measures.find_average_precision(reference, hypothesis)))\n",
    "    print(\"\\t RankDCG:\\t\\t{0}\".format(measures.find_rankdcg(reference, hypothesis), \"\\n\"))\n",
    "\n",
    "#Defining test cases\n",
    "L1 = [9, 4, 4, 2, 2, 2, 1, 1, 1, 1]\n",
    "L2 = [9, 4, 4, 2, 2, 1, 2, 1, 1, 1]\n",
    "L3 = [4, 4, 2, 9, 2, 2, 1, 1, 1, 1]\n",
    "L4 = [1, 4, 4, 2, 2, 2, 9, 1, 1, 1]\n",
    "L5 = [1, 4, 4, 2, 2, 2, 1, 1, 1, 9]\n",
    "L6 = [1, 1, 1, 1, 2, 2, 2, 4, 4, 9]\n",
    "\n",
    "print('list L1:', L1)\n",
    "print('list L2:', L2)\n",
    "print('list L3:', L3)\n",
    "print('list L4:', L4)\n",
    "print('list L5:', L5)\n",
    "print('list L6:', L6)\n",
    "print()\n",
    "\n",
    "\n",
    "#Testing:\n",
    "print(\"1. Perfect ordering: (L1, L1)\")\n",
    "test_measures(L1, L1)\n",
    "print()\n",
    "\n",
    "print(\"2. Slightly wose case (low ranks): (L1, L2)\")\n",
    "test_measures(L1, L2)\n",
    "print()\n",
    "\n",
    "print(\"3. Further worsen case (hight ranks): (L1, L3)\")\n",
    "test_measures(L1, L3)\n",
    "print()\n",
    "\n",
    "print(\"4. Placement of a high rank element into the low rank 'subgroup': (L1, L4)\")\n",
    "test_measures(L1, L4)\n",
    "print()\n",
    "\n",
    "print(\"5. Case #4 but with further misplacement of the hight rank element inside the low rank 'subgroup': (L1, L5)\")\n",
    "test_measures(L1, L5)\n",
    "print()\n",
    "\n",
    "print(\"6. The worst case (reverse ordering): (L1, L6)\")\n",
    "test_measures(L1, L6)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
