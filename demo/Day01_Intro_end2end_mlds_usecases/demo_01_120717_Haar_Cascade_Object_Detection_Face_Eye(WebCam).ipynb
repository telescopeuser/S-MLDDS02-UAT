{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Haar Cascade Object Detection Face & Eye (WebCam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"progressiveMedia-image js-progressiveMedia-image\" data-src=\"https://cdn-images-1.medium.com/max/1000/1*izQuwClzcsJoCw5ybQC01Q.png\" src=\"https://cdn-images-1.medium.com/max/1000/1*izQuwClzcsJoCw5ybQC01Q.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do object recognition/detection with cascade files, you first need cascade files. For the extremely popular tasks, these already exist. Detecting things like faces, cars, smiles, eyes, and license plates for example are all pretty prevalent.\n",
    "\n",
    "You can use Google to find various Haar Cascades of things you may want to detect. We will use a Face cascade and Eye cascade. You can find a few more at the root directory of Haar cascades. Note the license for using/distributing these Haar Cascades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "face: https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_frontalface_default.xml\n",
    "\n",
    "eye: https://github.com/opencv/opencv/blob/master/data/haarcascades/haarcascade_eye.xml\n",
    "\n",
    "To begin, download the haarcascade_eye.xml and haarcascade_frontalface_default.xml from the links above, and have these files in your project's directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "face = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "frame = cv2.VideoCapture(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pip install opencv-python to import cv2, and load in our face and eye cascades."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we begin our typical loop, the only new thing here is the creation of faces. \n",
    "\n",
    "We also want to find eyes, but, in a world of false positives, wouldn't it be prudent to logically make it so that we only find eyes in faces? Let's hope we're not looking for eyes that aren't in faces! \n",
    "\n",
    "In all seriousness, \"eye detection\" probably wouldn't find an eyeball laying around. Most eye detection uses the surrounding skin, eye lids, eye lashes, and eye brows to also make the detection. Thus, our next step is to break down the faces first, before getting to the eyes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "while 1:\n",
    "    ret, image = frame.read()\n",
    "    # To find faces in an image, we’ll start by making our image black and white because we don’t need color data to find faces.\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY) # converting the image color\n",
    "    face1 = face.detectMultiScale(gray, 1.3, 5) # deteting the face here\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in face1:\n",
    "        # drawing the rectange using its co-ordinates,color of rect,width of rect\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(240,140,0),2) \n",
    "        \n",
    "    eye1 = eye.detectMultiScale(gray, 1.3, 5) # detecting eye here\n",
    "    \n",
    "    for (x,y,w,h) in eye1:   \n",
    "        # drawing the rectange using ssame attributes as above\n",
    "        cv2.rectangle(image,(x,y),(x+w,y+h),(255,255,0),2) \n",
    "    \n",
    "    # If we find those, we'll go ahead and make some more rectangles. \n",
    "    cv2.imshow('img',image)\n",
    "    k = cv2.waitKey(30)\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "frame.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-be1d96b75a91>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'123.jpg'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mgray\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mrows\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "from cv2 import *\n",
    "import numpy as np\n",
    "face_cascade = CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "eye_cascade = CascadeClassifier('haarcascade_eye.xml')\n",
    "\n",
    "fname='./123.jpg'\n",
    "img = imread(fname)\n",
    "print img.shape\n",
    "gray = imread(fname, 0)\n",
    "rows,cols = gray.shape\n",
    "\n",
    "gray = np.array(gray, dtype='uint8')\n",
    "faces = face_cascade.detectMultiScale(gray, 1.3, 5, 0)\n",
    "print 'faces=', faces\n",
    "\n",
    "for (x,y,w,h) in faces:\n",
    "    rectangle(img, (x,y), ((x+w),(x+h)), (255,0,0), 2)\n",
    "    roi_gray = gray[y:y+h, x:x+w]\n",
    "    roi_color = img[y:y+h, x:x+w]\n",
    "    eyes = eye_cascade.detectMultiScale(roi_gray)\n",
    "    for (ex,ey, ew, eh) in eyes:\n",
    "        rectangle(roi_color, (x,y), ((x+w), (y+h)), (50, 50, 50), 3)\n",
    "    imshow('eyes=%s' % (eyes,), roi_color)\n",
    "\n",
    "imshow(\"img\", img)\n",
    "waitKey(0)\n",
    "destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
