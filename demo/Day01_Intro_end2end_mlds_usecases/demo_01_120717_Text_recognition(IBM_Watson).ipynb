{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Recognition using IBM Watson API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use IBM Watson and Python to read text from images for these instances:\n",
    "\n",
    "- license plate recognition (from real time video feed - cc cams, ip cams, etc.)\n",
    "- recognizing and storing id information from photos (sites that use photo-id verification)\n",
    "- converting photos of pages from books to documents, to pdf, etc.\n",
    "\n",
    "Basically, any kind of text information gathering from images and video feeds.\n",
    "You could create a script that would run over a video-feed (your ip cam) that looks over your parking spot and whenever it finds a car with a different plate number (that has illegally parked in your spot) than your car, it takes a snapshot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img class=\"irc_mi\" src=\"http://teaching.paganstudio.com/digitalfoundations/wp-content/uploads/2013/09/lpr_software_1.jpg\" alt=\"Image result for text recognition\" onload=\"google.aft&amp;&amp;google.aft(this)\" width=\"385\" height=\"286\" style=\"margin-top: 10px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Steps:**\n",
    "- Sign in to IBM Bluemix \n",
    "- Dashboard -> create service -> click \"watson\" under Services category -> visual recognition \n",
    "- Service credentials -> view credentials -> copy \"api_key\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To begin, do \"pip3 install watson_developer_cloud\" in command prompt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'c:\\users\\joon park\\appdata\\local\\programs\\python\\python36-32\\lib\\site-packages')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from watson_developer_cloud import VisualRecognitionV3 as vr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this exercise, I will be using the following car plate image.\n",
    "\n",
    "The URL is given https://steemitimages.com/0x0/http://i.imgsafe.org/203b33edda.jpg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://steemitimages.com/0x0/http://i.imgsafe.org/203b33edda.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace with your own api_key and image address below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance = vr(api_key = '5b4b65e25fc94f31b66e6fbf86870d938a381dee', version = '2017-06-07')\n",
    "img = instance.recognize_text(images_url='https://steemitimages.com/0x0/http://i.imgsafe.org/203b33edda.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "img returns the location of the characters and other relevant information. Thus, we will extract the text only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[mos] [pj] 15\n"
     ]
    }
   ],
   "source": [
    "print(img['images'][0]['text'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
